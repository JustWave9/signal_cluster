import os
import numpy as np
import scipy.io
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from extract_feature import extract_feature  # å‡è®¾ä½ çš„18ç»´ç‰¹å¾å‡½æ•°ä¿å­˜ä¸ºextract_feature.py

def get_true_label(filename):
    return int(filename.split('_')[1])

# ä¸»ç¨‹åºå‚æ•°
folder = r'D:\matrixlab\match_tar\test22TPLB'  # ä¿®æ”¹ä¸ºä½ çš„ä¿¡å·è·¯å¾„
Fs = 1e7  # é‡‡æ ·ç‡
save_path = "test3w.npz"  # ä¿å­˜æ ‡å‡†åŒ–ç‰¹å¾æ–‡ä»¶å

if os.path.exists(save_path):
    print("æ£€æµ‹åˆ°å·²ä¿å­˜ç‰¹å¾ï¼Œç›´æ¥åŠ è½½...")
    data = np.load(save_path, allow_pickle=True)
    X_scaled = data["X_scaled"]
    file_list = data["file_list"].tolist()
else:
    print("æœªæ£€æµ‹åˆ°ä¿å­˜æ–‡ä»¶ï¼Œå¼€å§‹æå–ç‰¹å¾...")
    features_list = []
    file_list = []


    for file in tqdm(os.listdir(folder)):
        if file.endswith('.mat'):
            path = os.path.join(folder, file)
            data = scipy.io.loadmat(path)
            if 'baseband_signal' in data:
                signal = data['baseband_signal']
                if signal.ndim > 1:
                    signal = signal.flatten()
                feature_vector = extract_feature(signal[np.newaxis, :], Fs)[0]
                features_list.append(feature_vector)
                file_list.append(file)

    X = np.array(features_list)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

# # ä¿å­˜æ ‡å‡†åŒ–ç‰¹å¾å’Œæ–‡ä»¶ååˆ—è¡¨
np.savez(save_path, X_scaled=X_scaled, file_list=file_list)
print(f"ç‰¹å¾æå–å®Œæ¯•ï¼Œä¿å­˜è‡³ {save_path}")

for i in range(len(file_list)):
    print(file_list[i])
    print(X_scaled[i])


# KMeansèšç±»
kmeans = KMeans(n_clusters=2, random_state=3)
labels = kmeans.fit_predict(X_scaled)

# è¾“å‡ºèšç±»ç»“æœ
print("æ–‡ä»¶å â†’ èšç±»ç±»åˆ«")
for fname, label in zip(file_list, labels):
    print(f"{fname} â†’ ç±»åˆ« {label}")

# æ„é€ çœŸå®æ ‡ç­¾
y_true = [get_true_label(fname)-1 for fname in file_list]
acc1 = accuracy_score(y_true, labels)
acc2 = accuracy_score(y_true, 1 - labels)
if acc2 > acc1:
    labels = 1 - labels  # æ ‡ç­¾å¯¹é½

# æ ¹æ®çœŸå®æ ‡ç­¾ç»˜åˆ¶æ•£ç‚¹å›¾
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
plt.figure(figsize=(8,6))
palette = sns.color_palette("bright", 2)

for label in np.unique(y_true):
    idx = np.array(y_true) == label
    plt.scatter(X_pca[idx, 0], X_pca[idx, 1],
                label=f'True Class {label}', alpha=0.7, s=50, c=[palette[label]])

plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")
plt.title(" PCA ")
plt.legend()
plt.grid(True)
plt.show()


# æ··æ·†çŸ©é˜µ
cm = confusion_matrix(y_true, labels)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Pred 0", "Pred 1"], yticklabels=["True 0", "True 1"])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("KMeans Confusion Matrix")
plt.tight_layout()
plt.show()

# åˆ†ç±»æŠ¥å‘Š
print(classification_report(y_true, labels, target_names=["Class 0", "Class 1"]))



# import os
# import numpy as np
# import scipy.io
# from scipy.fft import fft
# from scipy.signal import correlate, find_peaks
# import scipy.stats as stats
# import pywt
# from sklearn.cluster import KMeans
# from sklearn.preprocessing import StandardScaler
# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score
# import matplotlib.pyplot as plt
# import seaborn as sns
#
# def extract_features(signal, Fs):
#     signal = np.asarray(signal).flatten()
#     abs_signal = np.abs(signal)  # å¤ä¿¡å·è½¬ä¸ºæ¨¡å€¼
#     L = len(signal)
#     T = 1 / Fs
#     features = {}
#
#     # ä¸€ã€ç»Ÿè®¡ç‰¹å¾ï¼ˆåŸºäºæ¨¡å€¼ï¼‰
#     features['max'] = np.max(abs_signal)
#     features['min'] = np.min(abs_signal)
#     features['mean'] = np.mean(abs_signal)
#     features['median'] = np.median(abs_signal)
#     features['skewness'] = stats.skew(abs_signal, bias=False)
#     features['kurtosis'] = stats.kurtosis(abs_signal, fisher=False)
#     features['iqr'] = np.percentile(abs_signal, 75) - np.percentile(abs_signal, 25)
#     features['mad_mean'] = np.mean(np.abs(abs_signal - np.mean(abs_signal)))
#     features['mad_median'] = np.median(np.abs(abs_signal - np.median(abs_signal)))
#     features['rms'] = np.sqrt(np.mean(abs_signal**2))
#     features['std'] = np.std(abs_signal)
#     features['var'] = np.var(abs_signal)
#     features['percentile_50'] = np.sum(abs_signal <= np.percentile(abs_signal, 50)) / len(abs_signal)
#
#     # äºŒã€é¢‘è°±ç‰¹å¾ï¼ˆæ¨¡å€¼ï¼‰
#     fft_val = fft(signal)
#     P2 = np.abs(fft_val / L)
#     P1 = P2[:L // 2 + 1]
#     P1[1:-1] *= 2
#     features['fft_mean'] = np.mean(P1)
#     features['fft_max'] = np.max(P1)
#     features['fft_median'] = np.median(P1)
#     peaks, _ = find_peaks(P1)
#     features['fft_base'] = peaks[0] * Fs / L if len(peaks) > 0 else 0
#
#     # ä¸‰ã€å°æ³¢ç‰¹å¾ï¼ˆæ¨¡å€¼ï¼‰
#     coeffs = pywt.wavedec(abs_signal, 'db1', level=5)
#     features['wavelet_abs_mean'] = np.mean([np.mean(np.abs(c)) for c in coeffs])
#     features['wavelet_std'] = np.mean([np.std(c) for c in coeffs])
#     # features['wavelet_var'] = np.mean([np.var(c) for c in coeffs])
#
#     # å››ã€å·®åˆ†ç‰¹å¾ï¼ˆæ¨¡å€¼ï¼‰
#     diff = np.diff(abs_signal)
#     features['diff_mean'] = np.mean(diff)
#     # features['diff_abs_mean'] = np.mean(np.abs(diff))
#     features['diff_median'] = np.median(diff)
#     features['diff_abs_median'] = np.median(np.abs(diff))
#     # features['diff_sum'] = np.sum(np.abs(diff))
#
#     # äº”ã€ç†µï¼ˆæ¨¡å€¼ï¼‰
#     hist, _ = np.histogram(abs_signal, bins=256, density=True)
#     hist = hist[hist > 0]
#     features['entropy'] = -np.sum(hist * np.log2(hist))
#
#     # å…­ã€å‡ ä½•ç‰¹å¾ï¼ˆæ¨¡å€¼ï¼‰
#     features['x_dist_peak_valley'] = np.abs(np.argmax(abs_signal) - np.argmin(abs_signal)) * T
#     features['area'] = np.sum(abs_signal)
#     # features['num_max_peaks'] = len(find_peaks(abs_signal)[0])
#     # features['num_min_peaks'] = len(find_peaks(-abs_signal)[0])
#     features['zero_cross_rate'] = np.sum((abs_signal[:-1] * abs_signal[1:] < 0) | (abs_signal[:-1] == 0))
#
#     return features
#
# # ä»æ–‡ä»¶åä¸­æå–çœŸå®æ ‡ç­¾ï¼ˆç¬¬ä¸€ä¸ªä¸‹åˆ’çº¿åçš„æ•°å­—ï¼‰
# def get_true_label(filename):
#     return int(filename.split('_')[1])
#
#
# # === ä¸»ç¨‹åº ===
# folder = (r'D:\matrixlab\match_tar\test4m'
#           r'')  # ä¿®æ”¹ä¸ºä½ çš„ä¿¡å·è·¯å¾„
# Fs = 1e7  # é‡‡æ ·ç‡
#
# features_list = []
# file_list = []
#
# for file in os.listdir(folder):
#     if file.endswith('.mat'):
#         path = os.path.join(folder, file)
#         data = scipy.io.loadmat(path)
#         if 'baseband_signal' in data:
#             signal = data['baseband_signal'].flatten()
#             features = extract_features(signal, Fs)
#             features_list.append(list(features.values()))
#             file_list.append(file)
#             # âœ… æ‰“å°æ¯ä¸ªç‰¹å¾
#             print(f"\nğŸ“‚ æ–‡ä»¶: {file}")
#             for k, v in features.items():
#                 print(f"  {k:<25}: {v:.4e}")
#
# # è½¬æˆæ•°ç»„å¹¶æ ‡å‡†åŒ–
# X = np.array(features_list)
# scaler = StandardScaler()
# X_scaled = scaler.fit_transform(X)
#
# # KMeansèšç±»
# kmeans = KMeans(n_clusters=2, random_state=0)
# labels = kmeans.fit_predict(X_scaled)
#
# # è¾“å‡ºèšç±»ç»“æœ
# print("æ–‡ä»¶å â†’ èšç±»ç±»åˆ«")
# for fname, label in zip(file_list, labels):
#     print(f"{fname} â†’ ç±»åˆ« {label}")
#
# # æ„é€ çœŸå®æ ‡ç­¾åˆ—è¡¨
# y_true = [get_true_label(fname)-1 for fname in file_list]
# # å¯¹é½KMeansè¾“å‡ºæ ‡ç­¾ï¼ˆé˜²æ­¢0/1é¡ºåºé¢ å€’ï¼‰
# acc1 = accuracy_score(y_true, labels)
# acc2 = accuracy_score(y_true, 1 - labels)
# if acc2 > acc1:
#     labels = 1 - labels  # æ ‡ç­¾åè½¬å¯¹é½
#
# # æ··æ·†çŸ©é˜µ
# cm = confusion_matrix(y_true, labels)
#
# # å¯è§†åŒ–æ··æ·†çŸ©é˜µ
# plt.figure(figsize=(6, 5))
# sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
#             xticklabels=["Pred 0", "Pred 1"],
#             yticklabels=["True 0", "True 1"])
# plt.xlabel("Predicted Label")
# plt.ylabel("True Label")
# plt.title("KMeans Confusion Matrix")
# plt.tight_layout()
# plt.show()
#
# # åˆ†ç±»æŠ¥å‘Š
# print(classification_report(y_true, labels, target_names=["Class 0", "Class 1"]))
